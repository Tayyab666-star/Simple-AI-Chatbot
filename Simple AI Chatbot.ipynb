{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tayyab666-star/Simple-AI-Chatbot/blob/main/Simple%20AI%20Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNJvunVYPBCI",
        "outputId": "52db753f-fa49-4eb6-d751-49806187adc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Select operation:\n",
            "1. Add\n",
            "2. Subtract\n",
            "3. Multiply\n",
            "4. Divide\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Step 1: Install required libraries (Run this in Google Colab)\n",
        "!pip install transformers\n",
        "!pip install gradio\n",
        "\n",
        "# Step 2: Import necessary libraries\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import gradio as gr\n",
        "import torch\n",
        "\n",
        "# Step 3: Load pre-trained model and tokenizer\n",
        "model_name = \"microsoft/DialoGPT-small\"  # Using DialoGPT-small for the chatbot\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "# Step 4: Create the chatbot function\n",
        "def chatbot(user_input, chat_history_ids=None, max_length=50, temperature=0.7):\n",
        "    # Tokenize the user input\n",
        "    new_input_ids = tokenizer.encode(user_input + tokenizer.eos_token, return_tensors='pt')\n",
        "\n",
        "    # Append user input to the chat history\n",
        "    bot_input_ids = torch.cat([chat_history_ids, new_input_ids], dim=-1) if chat_history_ids is not None else new_input_ids\n",
        "\n",
        "    # Generate response using the model\n",
        "    chat_history_ids = model.generate(bot_input_ids, max_length=max_length, temperature=temperature, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "    # Decode the response\n",
        "    response = tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
        "\n",
        "    return response, chat_history_ids\n",
        "\n",
        "# Step 5: Define the Gradio interface function\n",
        "def interact_with_chatbot(user_input, max_length, temperature, chat_history):\n",
        "    response, chat_history = chatbot(user_input, chat_history, max_length, temperature)\n",
        "    return response, chat_history\n",
        "\n",
        "# Step 6: Create the Gradio UI\n",
        "with gr.Blocks(css=\".gradio-container {background-color: #f5f5f5; font-family: Arial; }\") as demo:\n",
        "    gr.Markdown(\"<h1 style='text-align: center; color: #4CAF50;'>Interactive Chatbot</h1>\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            chatbot_box = gr.Textbox(lines=6, label=\"Chat with the bot\", placeholder=\"Type your message here...\")\n",
        "        with gr.Column():\n",
        "            slider = gr.Slider(minimum=20, maximum=100, step=10, value=50, label=\"Max length of response\")\n",
        "            temp_slider = gr.Slider(minimum=0.1, maximum=1.0, step=0.1, value=0.7, label=\"Response creativity (Temperature)\")\n",
        "\n",
        "    chat_history = gr.State()  # To store the conversation history\n",
        "\n",
        "    submit_btn = gr.Button(\"Send Message\")\n",
        "\n",
        "    # Output area\n",
        "    chatbot_output = gr.Textbox(label=\"Bot Response\", lines=6)\n",
        "\n",
        "    # Button to clear chat\n",
        "    clear_btn = gr.Button(\"Clear Conversation\", variant=\"secondary\")\n",
        "\n",
        "    # Actions when the 'Send Message' button is clicked\n",
        "    submit_btn.click(interact_with_chatbot, [chatbot_box, slider, temp_slider, chat_history], [chatbot_output, chat_history])\n",
        "\n",
        "    # Action to clear chat\n",
        "    clear_btn.click(lambda: (\"\", None), outputs=[chatbot_output, chat_history])\n",
        "\n",
        "# Step 7: Launch the app\n",
        "demo.launch()\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykuXD5XCW53X"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJP4msxmbVW3wYxMI9KRN0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}